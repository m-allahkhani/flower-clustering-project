{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-allahkhani/flower-clustering-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm6WOsNK5jce"
      },
      "source": [
        "maryamm allahkhani\n",
        "shaghayegh shafiee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohy-uGrhk_6j"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy.spatial import ConvexHull\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "import cv2\n",
        "from statistics import mode\n",
        "import math\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available \",tf.test.gpu_device_name())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZm8kuCPL3rU",
        "outputId": "a008d727-efe5-451b-b739-6ad3ede3ceef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available  /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS6YU0nL5jch"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    image_pickle_file_path = '/content/sample_data/images.pkl'\n",
        "    label_pickle_file_path = '/content/sample_data/label.pkl'\n",
        "    drive.mount('/content/drive')\n",
        "    # with open(image_pickle_file_path, 'rb') as file:\n",
        "    #     images = pickle.load(file)\n",
        "\n",
        "    # with open(label_pickle_file_path, 'rb') as file:\n",
        "    #     labels = pickle.load(file)\n",
        "    images = np.load('drive/MyDrive/Colab Notebooks/images.pkl', allow_pickle = True)\n",
        "    labels = np.load('drive/MyDrive/Colab Notebooks/label.pkl', allow_pickle = True)\n",
        "    features = []\n",
        "    # pixel_locations = []\n",
        "    # hsv_values = []\n",
        "    for image in images:\n",
        "        n, m, _ = image.shape\n",
        "        indices = np.indices((n, m))\n",
        "\n",
        "        pixel_img = np.column_stack((indices[0].ravel(), indices[1].ravel()))\n",
        "        # pixel_locations.append(pixel_img)\n",
        "\n",
        "        hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "        hsv = hsv_image.reshape(n*m, -1)\n",
        "        # hsv_values.append(hsv)\n",
        "        feature_image = np.column_stack((hsv,pixel_img))\n",
        "        features.append(feature_image)\n",
        "    # return images, labels, pixel_locations, hsv_values , features\n",
        "    return images ,labels, features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoQeqXudbsdK"
      },
      "outputs": [],
      "source": [
        "# Classify the datapoints with the Random Forest Classifier\n",
        "def classify(feature_vectors, labels):\n",
        "\n",
        "\n",
        "    feature_vectors = np.array(feature_vectors)\n",
        "    scaler = StandardScaler()\n",
        "    normalized_features = scaler.fit_transform(feature_vectors[:, :])\n",
        "\n",
        "    weighted_features = np.empty([len(normalized_features), 8])\n",
        "    weighted_features[:, 0] = normalized_features[:, 0] * 3\n",
        "    weighted_features[:, 1] = normalized_features[:, 1] * 2\n",
        "    weighted_features[:, 2] = normalized_features[:, 2] * 2\n",
        "    weighted_features[:, 3] = normalized_features[:, 3] * 2\n",
        "    weighted_features[:, 4] = normalized_features[:, 4] * 2\n",
        "    weighted_features[:, 5] = normalized_features[:, 5] * 1\n",
        "    weighted_features[:, 6] = normalized_features[:, 6] * 1\n",
        "    weighted_features[:, 7] = normalized_features[:, 7] * 1\n",
        "\n",
        "    test_size = 0.2\n",
        "    X_train, X_test, y_train, y_test = train_test_split(weighted_features, labels, test_size=test_size, random_state=42)\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    return y_test,y_pred,accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLsdn84i5jci"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_flower_parts(features):\n",
        "    numberCluster = 3\n",
        "    scaler = StandardScaler()\n",
        "    width = np.max(features[:, 3])#center of the image\n",
        "    height = np.max(features[:, 4])\n",
        "    center_x =  width / 2\n",
        "    center_y = height / 2\n",
        "\n",
        "    #  horizontal and vertical space each pixel and the center\n",
        "    horizontal_space = np.abs(features[:, 3] - center_x)\n",
        "    vertical_space = np.abs(features[:, 4] - center_y)\n",
        "    horizontal_space_normalized = scaler.fit_transform(horizontal_space.reshape(-1, 1))\n",
        "    vertical_space_normalized = scaler.fit_transform(vertical_space.reshape(-1, 1))\n",
        "\n",
        "\n",
        "    num_components = 2    # number of components for GMM\n",
        "    original_hue_values = features[:, 0].copy()\n",
        "    gmm = GaussianMixture(n_components=num_components)\n",
        "    gmm.fit(original_hue_values.reshape(-1, 1))\n",
        "\n",
        "    # Assign each pixel to the most likely cluster based on its hue value\n",
        "    cluster_assignments = gmm.predict(original_hue_values.reshape(-1, 1))\n",
        "    arranged_hue_values = gmm.means_[cluster_assignments]\n",
        "    normalized_features = scaler.fit_transform(features[:, 1:5])\n",
        "    normalized_hue_values =scaler.fit_transform(arranged_hue_values.reshape(-1, 1))\n",
        "    weighted_features = np.empty([len(normalized_features), 7])\n",
        "    weighted_features[:, 0] = normalized_hue_values.flatten() * 12\n",
        "    weighted_features[:, 1] = normalized_features[:, 0] * 5\n",
        "    weighted_features[:, 2] = normalized_features[:, 1] * 8\n",
        "    weighted_features[:, 3] = normalized_features[:, 2] * 6\n",
        "    weighted_features[:, 4] = normalized_features[:, 3] * 6\n",
        "    weighted_features[:, 5] = horizontal_space_normalized.flatten() * 3  #  horizontal space\n",
        "    weighted_features[:, 6] = vertical_space_normalized.flatten() * 3  #  vertical space\n",
        "\n",
        "    kmeans = KMeans(n_clusters=numberCluster)\n",
        "    kmeans.fit(weighted_features)\n",
        "    cluster_labels = kmeans.predict(weighted_features)\n",
        "    # cluster_centers = kmeans.cluster_centers_\n",
        "\n",
        "\n",
        "    labeled_pixels = []\n",
        "    pixels = []\n",
        "    for i in range(len(features)):\n",
        "        pixel = [int(features[i][3]), int(features[i][4]), cluster_labels[i]]\n",
        "        labeled_pixels.append(pixel)\n",
        "        pixel2 = [int(features[i][0]), int(features[i][1]), int(features[i][2]), int(features[i][3]),int(features[i][4]), cluster_labels[i]]\n",
        "        pixels.append(pixel2)\n",
        "\n",
        "    clusters = [[] for _ in range(numberCluster)]\n",
        "    for i, pixel in enumerate(pixels):\n",
        "        cluster_label = pixel[5]\n",
        "        clusters[cluster_label].append([features[i][0], features[i][1], features[i][2], features[i][3],features[i][4], cluster_label])\n",
        "\n",
        "    return labeled_pixels,clusters,width,height,len(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQrIJ8QV5jci"
      },
      "outputs": [],
      "source": [
        "def show_cluster_image2(pixels, target_label,max_row,max_col): #image_width and height\n",
        "\n",
        "\n",
        "    # Initialize an empty image with dimensions based on the maximum row and column values\n",
        "    image = np.zeros((max_row + 1, max_col + 1, 3), dtype=np.uint8)\n",
        "\n",
        "    # Assign unique colors to each cluster label excluding target label\n",
        "    label_colors = {}\n",
        "    for pixel in pixels:\n",
        "        _, _, label = pixel\n",
        "        if label not in label_colors:\n",
        "            if label == target_label:\n",
        "                label_colors[label] = np.array([255, 0, 0], dtype=np.uint8)\n",
        "            else:\n",
        "                while True:\n",
        "                    color = np.random.randint(0, 256, size=3, dtype=np.uint8)\n",
        "                    if not np.array_equal(color, [255, 0, 0]): # Avoid red\n",
        "                        label_colors[label] = color\n",
        "                        break\n",
        "\n",
        "    # Fill the image pixels with the corresponding cluster label color\n",
        "    for pixel in pixels:\n",
        "        row, col, label = pixel\n",
        "        color = label_colors[label]\n",
        "        image[row, col] = color\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7p6Uguf5jck"
      },
      "outputs": [],
      "source": [
        "def show_image(image):\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcTrA0M5jck"
      },
      "outputs": [],
      "source": [
        "def show_cluster_image(pixels,max_row,max_col): #image_width and height\n",
        "\n",
        "\n",
        "    # Initialize an empty image with dimensions based on the maximum row and column values\n",
        "    image = np.zeros((max_row + 1, max_col + 1, 3), dtype=np.uint8)\n",
        "\n",
        "    # Assign unique colors to each cluster label\n",
        "    label_colors = {}\n",
        "    for pixel in pixels:\n",
        "        _, _, label = pixel\n",
        "        if label not in label_colors:\n",
        "            label_colors[label] = np.random.randint(0, 256, size=3, dtype=np.uint8)\n",
        "\n",
        "    # Fill the image pixels with the corresponding cluster label color\n",
        "    for pixel in pixels:\n",
        "        row, col, label = pixel\n",
        "        color = label_colors[label]\n",
        "        image[row, col] = color\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0MkxePG2FPv"
      },
      "outputs": [],
      "source": [
        "def find_label(num):\n",
        "    images2,labels,features = load_dataset()\n",
        "    for i in range(0,len(images2)):\n",
        "        if(labels[i]==num):\n",
        "            show_image(images2[i])\n",
        "            pixel_labels2,clusters,width,height,points_num= extract_flower_parts(features[i])\n",
        "            flower_index = find_flower_cluster(clusters,width,height,points_num)\n",
        "            show_cluster_image2(pixel_labels2,clusters[flower_index][0][5],width,height)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2LdO5kSZA0C"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_hue_change_coefficients(pixels, image_width, image_height):\n",
        "    x = np.array([pixel[4] for pixel in pixels])  # Column indices\n",
        "    y = np.array([pixel[3] for pixel in pixels])  # Row indices\n",
        "    hue = np.array([pixel[0] for pixel in pixels])  # Hue values\n",
        "\n",
        "    # distance to center\n",
        "    distance_to_center = np.sqrt((y - image_height/2)**2 + (x - image_width/2)**2)\n",
        "    max_distance = np.sqrt((image_height/2)**2 + (image_width/2)**2)\n",
        "    normalized_distance = distance_to_center / max_distance\n",
        "\n",
        "    # Left side\n",
        "    left_indices = x < image_width/2\n",
        "    a1 = np.sum((hue[left_indices] - np.mean(hue)) * normalized_distance[left_indices]) / np.sum(normalized_distance[left_indices]**2)\n",
        "\n",
        "    # Right side\n",
        "    right_indices = x >= image_width/2\n",
        "    a2 = np.sum((hue[right_indices] - np.mean(hue)) * normalized_distance[right_indices]) / np.sum(normalized_distance[right_indices]**2)\n",
        "\n",
        "    # Top side\n",
        "    top_indices = y < image_height/2\n",
        "    a3 = np.sum((hue[top_indices] - np.mean(hue)) * normalized_distance[top_indices]) / np.sum(normalized_distance[top_indices]**2)\n",
        "\n",
        "    # Bottom side\n",
        "    bottom_indices = y >= image_height/2\n",
        "    a4 = np.sum((hue[bottom_indices] - np.mean(hue)) * normalized_distance[bottom_indices]) / np.sum(normalized_distance[bottom_indices]**2)\n",
        "\n",
        "    return a1, a2, a3, a4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdQZfRgbZF1C"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_shape(max_width,max_height,flower_pixels): #max_width,max_height  of flower\n",
        "\n",
        "\n",
        "    # Calculate the area of the flower\n",
        "    flower_area = max_width * max_height * (flower_pixels / (max_width * max_height))\n",
        "\n",
        "    # Calculate the uncovered area for each shape\n",
        "    circle_radius = math.sqrt(flower_area / math.pi)\n",
        "    circle_area = math.pi * circle_radius ** 2\n",
        "    circle_uncovered_area = circle_area - flower_area\n",
        "\n",
        "    triangle_side = math.sqrt((4 * flower_area) / (math.sqrt(3) * 3))\n",
        "    triangle_area = (math.sqrt(3) / 4) * triangle_side ** 2\n",
        "    triangle_uncovered_area = triangle_area - flower_area\n",
        "\n",
        "    rectangle_width = math.sqrt(flower_area / 2)\n",
        "    rectangle_height = 2 * rectangle_width\n",
        "    rectangle_area = rectangle_width * rectangle_height\n",
        "    rectangle_uncovered_area = rectangle_area - flower_area\n",
        "    # min_uncovered_area = min(circle_uncovered_area, triangle_uncovered_area, rectangle_uncovered_area)\n",
        "\n",
        "    # if min_uncovered_area == circle_uncovered_area:\n",
        "    #     min_shape = \"circle\"\n",
        "    # elif min_uncovered_area == triangle_uncovered_area:\n",
        "    #     min_shape = \"triangle\"\n",
        "    # else:\n",
        "    #     min_shape = \"rectangle\"\n",
        "\n",
        "    return  circle_area/flower_pixels, triangle_area/flower_pixels, rectangle_area/flower_pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dnEhI3ggX1l"
      },
      "outputs": [],
      "source": [
        "def calculate_column_averages(feature_vectors):\n",
        "    # Convert the list of feature vectors to a numpy array\n",
        "    feature_vectors_array = np.array(feature_vectors)\n",
        "\n",
        "    # Calculate the mean of each column\n",
        "    column_averages = np.mean(feature_vectors_array, axis=0)\n",
        "\n",
        "    # Convert the numpy array to a list and return it\n",
        "    return column_averages.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKtz4V1JZKpZ"
      },
      "outputs": [],
      "source": [
        "def get_features(clusters,points_num, image_width, image_height):\n",
        "    features_vectors =[]\n",
        "    for cluster in clusters:\n",
        "        cluster_array = np.array(cluster)\n",
        "        min_row = np.min(cluster_array[:, 3])\n",
        "        max_row = np.max(cluster_array[:, 3])\n",
        "        min_col = np.min(cluster_array[:, 4])\n",
        "        max_col = np.max(cluster_array[:, 4])\n",
        "        width = max_col-min_col\n",
        "        height = max_row-min_row\n",
        "\n",
        "        most_hue = mode(cluster_array[:, 0] )\n",
        "        # features_vector = []\n",
        "        hue_changes1,hue_changes2,hue_changes3,hue_changes4 = calculate_hue_change_coefficients(cluster, image_width, image_height)\n",
        "        circle,traingle,rectangle = calculate_shape(width,height,points_num) #width,height\n",
        "        features_vector = [most_hue,hue_changes1,hue_changes2,hue_changes3,hue_changes4,circle,traingle,rectangle]\n",
        "        features_vectors.append(features_vector)\n",
        "\n",
        "    return calculate_column_averages(features_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_z5DYohYX_m"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def MatrixCal(true_labels,predicted_labels):\n",
        "\n",
        "# Create the confusion matrix\n",
        "   confusion_mat = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Create a pandas DataFrame for better visualization\n",
        "   confusion_df = pd.DataFrame(confusion_mat, index=['True1', 'True2', 'True3', 'True4', 'True5', 'True6', 'True7'],\n",
        "                             columns=['Pred1', 'Pred2', 'Pred3', 'Pred4', 'Pred5', 'Pred6', 'Pred7'])\n",
        "\n",
        "   print(\"Confusion Matrix:\")\n",
        "   print(confusion_df)\n",
        "\n",
        "# Calculate the precision, recall, f1-score, and accuracy\n",
        "   precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "   recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "   f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "   accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "   print(\"\\nPrecision:\", precision)\n",
        "   print(\"Recall:\", recall)\n",
        "   print(\"F1-score:\", f1)\n",
        "   print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgH6_c6wZRbD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_accuracy2(features_vector,labels):\n",
        "\n",
        "\n",
        "    # random_indices = random.sample(range(len(images2)), num)\n",
        "    # images = [images2[i] for i in random_indices]\n",
        "    # labels = [labels2[i] for i in random_indices]\n",
        "    # features = [features2[i] for i in random_indices]\n",
        "\n",
        "        # Replace NaN values with integers based on the other lists in features_vector\n",
        "        # for j in range(len(v)):\n",
        "        #     if np.isnan(v[j]):\n",
        "        #         v[j] = int(np.nanmean(features_vector_arr[:, j]))  # Replace NaN with the mean of the non-NaN values for that feature\n",
        "\n",
        "        # features_vector.append(v)\n",
        "\n",
        "\n",
        "    y_test,y_pred =classify(features_vector, labels)\n",
        "    MatrixCal(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDdFsEm5nu5e"
      },
      "outputs": [],
      "source": [
        "get_accuracy2()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ANtFTgM2FPw"
      },
      "outputs": [],
      "source": [
        "def remove_cluster(clusters,del_index, rows, cols, pixels_num,labels):\n",
        "\n",
        "    remaining_clusters = list(clusters)\n",
        "\n",
        "    # accuracies = []\n",
        "    # for i, cluster in enumerate(remaining_clusters):\n",
        "    if del_index >= 0:\n",
        "      result = np.delete(clusters, del_index, axis=0)\n",
        "    else: result = remaining_clusters\n",
        "    features_vector = get_features(remaining_clusters[:del_index] + remaining_clusters[del_index+1:],pixels_num,rows, cols )\n",
        "        # _ ,_ , accuracy = classify(features,labels)\n",
        "        # accuracies.append(accuracy)\n",
        "\n",
        "    # max_accuracy_index = accuracies.index(max(accuracies))\n",
        "    # print(\"Removing cluster:\", remaining_clusters[max_accuracy_index])\n",
        "    # del remaining_clusters[max_accuracy_index]\n",
        "\n",
        "    return features_vector , result\n",
        "\n",
        "\n",
        "    # final_cluster_index = clusters.index(remaining_clusters[0])\n",
        "    # print(\"Final cluster:\", remaining_clusters[0] + \", Index:\", final_cluster_index)\n",
        "    # return final_cluster_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6i_kLNnLMxo"
      },
      "outputs": [],
      "source": [
        "def find_flower_cluster(features,labels):\n",
        "    images_flower_index = []\n",
        "    images_cluster = []\n",
        "    images_width = []\n",
        "    images_height = []\n",
        "    images_points_num = []\n",
        "    images_pixel_lables = []\n",
        "    cur_feature_vector = []\n",
        "    cur_clusters = []\n",
        "    for i, image in enumerate(features):\n",
        "      pixel_labels,clusters,width,height,points_num= extract_flower_parts(features[i])\n",
        "      images_width.append(width)\n",
        "      images_cluster.append(clusters)\n",
        "      images_height.append(height)\n",
        "      images_points_num.append(points_num)\n",
        "      images_pixel_lables.append(pixel_labels)\n",
        "\n",
        "    cluster_num = len(images_cluster[0])\n",
        "    images_cluster_origin = images_cluster # copy original clusters\n",
        "\n",
        "    for i in range(0,len(features)):\n",
        "        fv,c = remove_cluster(images_cluster[i],-1,images_width[i], images_height[i], images_points_num[i],labels)\n",
        "        cur_feature_vector.append(fv)\n",
        "        cur_clusters.append(c)\n",
        "    # print(cur_feature_vector)\n",
        "    _, _, pre_accuracy = classify(cur_feature_vector,labels)\n",
        "    print(pre_accuracy)\n",
        "\n",
        "\n",
        "    del_index = 0\n",
        "    while cluster_num > 1:\n",
        "      print(f\"del_index is {del_index}\")\n",
        "      for i in range(0,len(features)):\n",
        "        cur_feature_vector[i],cur_clusters[i] = remove_cluster(images_cluster[i],del_index,images_width[i], images_height[i], images_points_num[i],labels)\n",
        "      print(cur_feature_vector)\n",
        "      _, _, cur_accuracy = classify(cur_feature_vector,labels)\n",
        "      # print(cur_feature_vector)\n",
        "      if cur_accuracy > pre_accuracy:\n",
        "        cluster_num -= 1\n",
        "        images_cluster = cur_clusters\n",
        "        del_index = 0\n",
        "        pre_accuracy = cur_accuracy\n",
        "      else :\n",
        "        del_index += 1\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(0,len(features)) :\n",
        "      images_flower_index.append(images_cluster_origin.index(images_cluster[i][0]))\n",
        "\n",
        "\n",
        "    return images_cluster_origin,images_flower_index,images_width,images_height , images_pixel_lables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSu4fI-X2FPw"
      },
      "outputs": [],
      "source": [
        "def test_finding_flower(num):\n",
        "    images2, labels2, features2 = load_dataset()\n",
        "\n",
        "    random_indices = random.sample(range(len(images2)), num)\n",
        "\n",
        "    images = [images2[i] for i in random_indices]\n",
        "    labels = [labels2[i] for i in random_indices]\n",
        "    features = [features2[i] for i in random_indices]\n",
        "\n",
        "    images_cluster,images_flower_index,images_width,images_height, images_pixel_lables = find_flower_cluster(features,labels)\n",
        "    for j in range(0,num):\n",
        "        print(j)\n",
        "        show_image(images[j])\n",
        "        show_cluster_image2(images_pixel_lables[j],images_cluster[j][images_flower_index[j]][0][5],images_width[j],images_height[j])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdaQk1lm23Qu",
        "outputId": "912a50ed-5e06-40c7-a004-7aa1f9688bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "test_finding_flower(60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCvGwyXr2FPw"
      },
      "outputs": [],
      "source": [
        "def all():\n",
        "    images2, labels2, features2 = load_dataset()\n",
        "\n",
        "    random_indices = random.sample(range(len(images2)), 50)\n",
        "\n",
        "    images = [images2[i] for i in random_indices]\n",
        "    labels = [labels2[i] for i in random_indices]\n",
        "    features = [features2[i] for i in random_indices]\n",
        "\n",
        "    features_vector = []\n",
        "    for i in range(0,len(images)):\n",
        "        # show_image(images[i])\n",
        "        pixel_labels2,clusters,image_width, image_height ,points_num= extract_flower_parts(features[i])\n",
        "        flower_index = find_flower_cluster(clusters,image_width, image_height,points_num)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}